{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from utils.SineDataSet import get_batch\n",
    "from utils.Generator import Generator\n",
    "from utils.Critic import Critic\n",
    "from utils.loss_functions import get_Cη_loss, get_Cyδ_loss, get_G_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize generators and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator().cuda()\n",
    "Cη = Critic().cuda()\n",
    "Cyδ = Critic().cuda()\n",
    "\n",
    "lr, betas = 2e-4, (.5, .9)\n",
    "optimizer_G = torch.optim.Adam(G.parameters(), lr=lr, betas=betas)\n",
    "optimizer_Cη = torch.optim.Adam(Cη.parameters(), lr=lr, betas=betas)\n",
    "optimizer_Cyδ = torch.optim.Adam(Cyδ.parameters(), lr=lr, betas=betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_errors_to_groundtruth = []\n",
    "ticks = []\n",
    "losses_Cη = []\n",
    "losses_Cyδ = []\n",
    "losses_G = []\n",
    "tick = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    with torch.no_grad():\n",
    "        y, yδ, η = get_batch()\n",
    "        y_approximation, η_approximation, y_renoised = G.apply_for_training(yδ)\n",
    "        mean_errors_to_groundtruth.append(torch.norm(y - y_approximation, dim=1).mean().item())\n",
    "        ticks.append(time.time() - tick)\n",
    "\n",
    "    optimizer_Cη.zero_grad()\n",
    "    loss_Cη = get_Cη_loss(Cη, η, η_approximation)\n",
    "    losses_Cη.append(loss_Cη.item())\n",
    "    loss_Cη.backward()\n",
    "    optimizer_Cη.step()\n",
    "\n",
    "    optimizer_Cyδ.zero_grad()\n",
    "    loss_Cyδ = get_Cyδ_loss(Cyδ, yδ, y_renoised) \n",
    "    losses_Cyδ.append(loss_Cyδ.item())\n",
    "    loss_Cyδ.backward()\n",
    "    optimizer_Cyδ.step()\n",
    "\n",
    "    optimizer_G.zero_grad()\n",
    "    loss_G = get_G_loss(G, Cη, Cyδ, yδ)\n",
    "    losses_G.append(loss_G.item())\n",
    "    loss_G.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mean_errors_to_groundtruth.append(torch.norm(y - y_approximation, dim=1).mean().item())\n",
    "        ticks.append(time.time() - tick)\n",
    "\n",
    "    if not len(mean_errors_to_groundtruth) % 100:\n",
    "        torch.save(G.state_dict(), f'trained_models/gtfd/G_state_{len(mean_errors_to_groundtruth)}.pt')\n",
    "        np.save(f'trained_models/gtfd/mean_errors_to_groundtruth.npy', mean_errors_to_groundtruth)\n",
    "        np.save(f'trained_models/gtfd/ticks.npy', ticks)\n",
    "        np.save(f'trained_models/gtfd/losses_Cη.npy', losses_Cη)\n",
    "        np.save(f'trained_models/gtfd/losses_Cyδ.npy', losses_Cyδ)\n",
    "        np.save(f'trained_models/gtfd/losses_G.npy', losses_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
